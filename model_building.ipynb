{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "Here we will choose and built model, which could work in real world. This is explonatory part, working model with code, where we prepare our data and send it to model you can find in separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing main data analysis libraries  \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "#importing main visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading prepared data\n",
    "train = pd.read_csv('C:/Users/user/Projects/Health_Insurance_Sell_Analysis/prepared_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x_train:  (295160, 7) \n",
      " y_train: (295160,) \n",
      " x_test: (73790, 7) \n",
      " y_test: (73790,)\n"
     ]
    }
   ],
   "source": [
    "#split our dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train.drop(columns= 'response', axis = 1), \n",
    "    train['response'], \n",
    "    test_size=0.2)\n",
    "\n",
    "print(' x_train: ',X_train.shape, '\\n',\n",
    "      'y_train:',y_train.shape,'\\n',\n",
    "      'x_test:',X_test.shape,'\\n',\n",
    "      'y_test:',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training models\n",
    "\n",
    "In this part we will train our main models. I train a lot of models, because we can't say for sure which model would be preferable, so we will train several models, which could work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='gini', max_depth=None, max_features='auto',\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "et_clf = ExtraTreesClassifier()\n",
    "et_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier with RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('svm_clf',\n",
       "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "rbf_kernel_sv_clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm_clf', SVC(kernel = 'rbf'))\n",
    "])\n",
    "\n",
    "rbf_kernel_sv_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\n",
       "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
       "              random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(loss = 'log')\n",
    "\n",
    "sgd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "kn_clf = KNeighborsClassifier()\n",
    "\n",
    "kn_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "naive_bayes_clf = CategoricalNB()\n",
    "\n",
    "naive_bayes_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving models without tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "clfs = [rf_clf,rbf_kernel_sv_clf, sgd_clf,kn_clf, et_clf, naive_bayes_clf]\n",
    "names = ['rf_clf_wt.joblib', 'rbf_kernel_sv_clf_wt.joblib', 'sgd_clf_wt.joblib', 'kn_clf_wt.joblib', 'et_clf_wt.joblib','naive_bayes_clf_wt.joblib']\n",
    "for clf in clfs:\n",
    "    for name in names:\n",
    "            dump(clf, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance score\n",
    "Here we will check performance of our model, our main goal to get most efficient model. We will focus on ROC AUC, but we have recall in priority. Our goal is to have the widest range of clients, to have our sales managers reach the largest number of potential customers, which would buy our insurance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "def score(clfs):\n",
    "    for clf in clfs:\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(\n",
    "            clf.__class__.__name__, '\\n',\n",
    "            'Accuracy score: ',accuracy_score(y_test, y_pred), '\\n',\n",
    "            'Precision score: ',precision_score(y_test, y_pred, zero_division = 1), '\\n',\n",
    "            'Recall score: ',recall_score(y_test, y_pred, zero_division = 1), '\\n',\n",
    "            'F1 score: ',f1_score(y_test, y_pred, zero_division = 1), '\\n',\n",
    "            'ROC AUC score: ',roc_auc_score(y_test, y_pred), '\\n',\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier \n",
      " Accuracy score:  0.856687898089172 \n",
      " Precision score:  0.314643188137164 \n",
      " Recall score:  0.1513091922005571 \n",
      " F1 score:  0.20434880746369724 \n",
      " ROC AUC score:  0.5528358041539698 \n",
      "\n",
      "Pipeline \n",
      " Accuracy score:  0.8783710529882098 \n",
      " Precision score:  1.0 \n",
      " Recall score:  0.0 \n",
      " F1 score:  0.0 \n",
      " ROC AUC score:  0.5 \n",
      "\n",
      "SGDClassifier \n",
      " Accuracy score:  0.8783710529882098 \n",
      " Precision score:  1.0 \n",
      " Recall score:  0.0 \n",
      " F1 score:  0.0 \n",
      " ROC AUC score:  0.5 \n",
      "\n",
      "KNeighborsClassifier \n",
      " Accuracy score:  0.8565252744274292 \n",
      " Precision score:  0.3314512756168967 \n",
      " Recall score:  0.1766016713091922 \n",
      " F1 score:  0.2304281456712946 \n",
      " ROC AUC score:  0.5636383346903132 \n",
      "\n",
      "CategoricalNB \n",
      " Accuracy score:  0.7177666350453991 \n",
      " Precision score:  0.2847073356828834 \n",
      " Recall score:  0.8730919220055711 \n",
      " F1 score:  0.4293933914187079 \n",
      " ROC AUC score:  0.784675252061954 \n",
      "\n",
      "ExtraTreesClassifier \n",
      " Accuracy score:  0.8541672313321589 \n",
      " Precision score:  0.308861301369863 \n",
      " Recall score:  0.16077994428969358 \n",
      " F1 score:  0.2114750494614201 \n",
      " ROC AUC score:  0.5554806147430108 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "clfs = [rf_clf,rbf_kernel_sv_clf, sgd_clf,kn_clf, naive_bayes_clf, et_clf]\n",
    "score(clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Choosing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After scoring, we can see, how our models worked. In my opinion we should tune next models: KNeighbors and Extra Trees Classifier. We have perspective Naive Bayes model, but we will try it, if others won't work well. They are looking the most perspective in this case. We will tune them in next step. \n",
    "\n",
    "But this are not our final models, because later we will try ensemble models with Naive Bayes, which working very well with our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "\n",
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Search\n",
    "Here we explore the widest range of parameters, and then we move on to more detailed ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv_et_clf = ExtraTreesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [32, 64, 128,  256, 512]\n",
    "max_featurese = ['auto', 'sqrt', 'log2']\n",
    "max_depth = [32, 64, 128, 256, 512]\n",
    "min_samples_leaf = [1, 2, 5, 10, 15, 20, 25, 30]\n",
    "criterion = ['entropy', 'gini']\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_param_et_clf = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_features': max_featurese,\n",
    "    'criterion' : criterion,\n",
    "    'bootstrap': bootstrap,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv_et_clf_f = RandomizedSearchCV(estimator= rscv_et_clf, param_distributions= random_param_et_clf,\n",
    "                                   cv = 5, scoring= 'recall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=ExtraTreesClassifier(bootstrap=False,\n",
       "                                                  ccp_alpha=0.0,\n",
       "                                                  class_weight=None,\n",
       "                                                  criterion='gini',\n",
       "                                                  max_depth=None,\n",
       "                                                  max_features='auto',\n",
       "                                                  max_leaf_nodes=None,\n",
       "                                                  max_samples=None,\n",
       "                                                  min_impurity_decrease=0.0,\n",
       "                                                  min_impurity_split=None,\n",
       "                                                  min_samples_leaf=1,\n",
       "                                                  min_samples_split=2,\n",
       "                                                  min_weight_fraction_leaf=0.0,\n",
       "                                                  n_estimators=100, n_jobs=...\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'criterion': ['entropy', 'gini'],\n",
       "                                        'max_depth': [32, 64, 128, 256, 512],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 5, 10, 15,\n",
       "                                                             20, 25, 30],\n",
       "                                        'n_estimators': [32, 64, 128, 256,\n",
       "                                                         512]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='recall', verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv_et_clf_f.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='entropy', max_depth=128, max_features='sqrt',\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=512,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv_et_clf_f.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv_et_clf_2 = ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
    "                     criterion='entropy', max_depth=128, max_features='sqrt',\n",
    "                     max_leaf_nodes=None, max_samples=None,\n",
    "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                     min_samples_leaf=1, min_samples_split=2,\n",
    "                     min_weight_fraction_leaf=0.0, n_estimators=512,\n",
    "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
    "                     warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='entropy', max_depth=128, max_features='sqrt',\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=512,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rscv_et_clf_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesClassifier \n",
      " Accuracy score:  0.8551836292180512 \n",
      " Precision score:  0.32345894140710085 \n",
      " Recall score:  0.16381687810259238 \n",
      " F1 score:  0.21748681898066782 \n",
      " ROC AUC score:  0.5579146190435712 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "score([rscv_et_clf_2])\n",
    "\n",
    "#we improved our accuracy, but it's not most important, because now we don't have to check max_features, bootstrap params\n",
    "#and we can concentrate on GridSearch, which could improve our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [128,  256, 512]\n",
    "max_featurese = ['sqrt']\n",
    "max_depth = [64, 128, 256]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [False]\n",
    "criterion = ['entropy']\n",
    "\n",
    "grid_param_et_clf = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_features': max_featurese,\n",
    "    'criterion' : criterion,\n",
    "    'bootstrap': bootstrap,\n",
    "    'max_depth': max_depth,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv_et_clf = ExtraTreesClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv_et_clf_f =  GridSearchCV(estimator= gscv_et_clf, param_grid= grid_param_et_clf, cv = 3, scoring= 'recall')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,\n",
       "                                            class_weight=None, criterion='gini',\n",
       "                                            max_depth=None, max_features='auto',\n",
       "                                            max_leaf_nodes=None,\n",
       "                                            max_samples=None,\n",
       "                                            min_impurity_decrease=0.0,\n",
       "                                            min_impurity_split=None,\n",
       "                                            min_samples_leaf=1,\n",
       "                                            min_samples_split=2,\n",
       "                                            min_weight_fraction_leaf=0.0,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            oob_score=False, random_state=None,\n",
       "                                            verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'bootstrap': [False], 'criterion': ['entropy'],\n",
       "                         'max_depth': [64, 128, 256], 'max_features': ['sqrt'],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'n_estimators': [128, 256, 512]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='recall', verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv_et_clf_f.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                     criterion='entropy', max_depth=128, max_features='sqrt',\n",
       "                     max_leaf_nodes=None, max_samples=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=128,\n",
       "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
       "                     warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv_et_clf_f.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV \n",
      " Accuracy score:  0.8550481094999323 \n",
      " Precision score:  0.3215926493108729 \n",
      " Recall score:  0.16216216216216217 \n",
      " F1 score:  0.21560574948665298 \n",
      " ROC AUC score:  0.557125886025075 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "score([gscv_et_clf_f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Tree Conclusion\n",
    "\n",
    "As we can see this model wasn't effective after tuning, but we won't give up, because we have a lot of others classificator, which we will tune and try them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighbors Classifier\n",
    "Here we will explore our next classifier, which looks very perspective. Here we won't use Random Search, because our model teaching very fast and we don't have a lot paramets, so we started with GridSearch and look how it would work. Here we will concentrate on ROC AUC, it might give us better results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "scv_knn_clf = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_size = list(range(1,30))\n",
    "n_neighbors = list(range(1,30))\n",
    "p = [1,2]\n",
    "\n",
    "random_param_knn_clf = {\n",
    "    'p': p,\n",
    "    'n_neighbors': n_neighbors,\n",
    "    'leaf_size' : leaf_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv_knn_clf_f =  RandomizedSearchCV(estimator= scv_knn_clf, param_distributions = random_param_knn_clf, cv = 3, scoring= 'roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=KNeighborsClassifier(algorithm='auto',\n",
       "                                                  leaf_size=30,\n",
       "                                                  metric='minkowski',\n",
       "                                                  metric_params=None,\n",
       "                                                  n_jobs=None, n_neighbors=5,\n",
       "                                                  p=2, weights='uniform'),\n",
       "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'leaf_size': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29],\n",
       "                                        'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8,\n",
       "                                                        9, 10, 11, 12, 13, 14,\n",
       "                                                        15, 16, 17, 18, 19, 20,\n",
       "                                                        21, 22, 23, 24, 25, 26,\n",
       "                                                        27, 28, 29],\n",
       "                                        'p': [1, 2]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv_knn_clf_f.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=5, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=29, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv_knn_clf_f.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "gscv_knn_clf_s = KNeighborsClassifier(algorithm='auto', leaf_size=5, metric='minkowski',\n",
    "                     metric_params=None, n_jobs=None, n_neighbors=29, p=2,\n",
    "                     weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=5, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=29, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv_knn_clf_s.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier \n",
      " Accuracy score:  0.8739531101775309 \n",
      " Precision score:  0.3805668016194332 \n",
      " Recall score:  0.041478212906784336 \n",
      " F1 score:  0.07480354123147319 \n",
      " ROC AUC score:  0.5160114123630097 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "score([gscv_knn_clf_s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "We improve our accuracy score on 2% and precision on 5, but we lost a lot in our recall. Unfortunately, this model wasn't worked to good. So we can say, that we can drop her and continue finding better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble models\n",
    "Here we will test some of our models in ensemble, in my opinion Naive Bayes and SGDClassifier together could make a better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_catnb_clf_f  = CategoricalNB()\n",
    "vt_rfc_clf_f  = RandomForestClassifier()\n",
    "vt_sgd_clf_f  = SGDClassifier(loss = 'log')\n",
    "vt_knn_clf_f  = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf_f = VotingClassifier(\n",
    "    estimators = [('rf', vt_catnb_clf_f), ('nb', vt_rfc_clf_f), ('sgd', vt_sgd_clf_f), ('knn', vt_knn_clf_f)],\n",
    "    voting = 'hard'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf',\n",
       "                              CategoricalNB(alpha=1.0, class_prior=None,\n",
       "                                            fit_prior=True)),\n",
       "                             ('nb',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     ccp_alpha=0.0,\n",
       "                                                     class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth=None,\n",
       "                                                     max_features='auto',\n",
       "                                                     max_leaf_nodes=None,\n",
       "                                                     max_samples=None,\n",
       "                                                     min_impurity_decrease=0.0,\n",
       "                                                     min_impurity_split=None,\n",
       "                                                     min_samples_leaf=1,\n",
       "                                                     min_samples_split=2,\n",
       "                                                     min...\n",
       "                                            max_iter=1000, n_iter_no_change=5,\n",
       "                                            n_jobs=None, penalty='l2',\n",
       "                                            power_t=0.5, random_state=None,\n",
       "                                            shuffle=True, tol=0.001,\n",
       "                                            validation_fraction=0.1, verbose=0,\n",
       "                                            warm_start=False)),\n",
       "                             ('knn',\n",
       "                              KNeighborsClassifier(algorithm='auto',\n",
       "                                                   leaf_size=30,\n",
       "                                                   metric='minkowski',\n",
       "                                                   metric_params=None,\n",
       "                                                   n_jobs=None, n_neighbors=5,\n",
       "                                                   p=2, weights='uniform'))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf_f.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier \n",
      " Accuracy score:  0.8694809594796042 \n",
      " Precision score:  0.3569261880687563 \n",
      " Recall score:  0.07788196359624931 \n",
      " F1 score:  0.1278638051254188 \n",
      " ROC AUC score:  0.5291147940808593 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "score([voting_clf_f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft voting with params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "vt_catnb_clf_s  = CategoricalNB()\n",
    "vt_rfc_clf_s  = RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
    "                     criterion='entropy', max_depth=128, max_features='sqrt',\n",
    "                     max_leaf_nodes=None, max_samples=None,\n",
    "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                     min_samples_leaf=1, min_samples_split=2,\n",
    "                     min_weight_fraction_leaf=0.0, n_estimators=128,\n",
    "                     n_jobs=None, oob_score=False, random_state=None, verbose=0,\n",
    "                     warm_start=False)\n",
    "vt_sgd_clf_s  = SGDClassifier(loss = 'log')\n",
    "vt_knn_clf_s  = KNeighborsClassifier(algorithm='auto', leaf_size=5, metric='minkowski',\n",
    "                     metric_params=None, n_jobs=None, n_neighbors=29, p=2,\n",
    "                     weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf_s = VotingClassifier(\n",
    "    estimators = [('nb', vt_catnb_clf_s), ('sgd', vt_sgd_clf_s)],\n",
    "    voting = 'soft'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('nb',\n",
       "                              CategoricalNB(alpha=1.0, class_prior=None,\n",
       "                                            fit_prior=True)),\n",
       "                             ('sgd',\n",
       "                              SGDClassifier(alpha=0.0001, average=False,\n",
       "                                            class_weight=None,\n",
       "                                            early_stopping=False, epsilon=0.1,\n",
       "                                            eta0=0.0, fit_intercept=True,\n",
       "                                            l1_ratio=0.15,\n",
       "                                            learning_rate='optimal', loss='log',\n",
       "                                            max_iter=1000, n_iter_no_change=5,\n",
       "                                            n_jobs=None, penalty='l2',\n",
       "                                            power_t=0.5, random_state=None,\n",
       "                                            shuffle=True, tol=0.001,\n",
       "                                            validation_fraction=0.1, verbose=0,\n",
       "                                            warm_start=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf_s.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier \n",
      " Accuracy score:  0.7285946605231061 \n",
      " Precision score:  0.2934815373021854 \n",
      " Recall score:  0.8592388306674021 \n",
      " F1 score:  0.4375228198286757 \n",
      " ROC AUC score:  0.7847681213978185 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "score([voting_clf_s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Unfortunately we didn't get big results, but we should try another one. We have AdaBoost, maybe it would work well with our Naive Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_nb_clf = CategoricalNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab_clf_f = AdaBoostClassifier(base_estimator= ab_nb_clf, n_estimators= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=CategoricalNB(alpha=1.0, class_prior=None,\n",
       "                                                fit_prior=True),\n",
       "                   learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab_clf_f.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier \n",
      " Accuracy score:  0.8771513755251389 \n",
      " Precision score:  1.0 \n",
      " Recall score:  0.0 \n",
      " F1 score:  0.0 \n",
      " ROC AUC score:  0.5 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "score([ab_clf_f])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble conclusion\n",
    "As we can see our ensemble and grid search methods didn't work well, but we don't lost our faith, because our best model now is Naive Bayes and we can try different Naive Bayes, not only categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB, GaussianNB, BernoulliNB\n",
    "\n",
    "brn_nb_clf = BernoulliNB()\n",
    "compl_nb_clf = ComplementNB()\n",
    "gaus_nb_clf = GaussianNB()\n",
    "\n",
    "compl_nb_clf.fit(X_train, y_train)\n",
    "gaus_nb_clf.fit(X_train, y_train)\n",
    "brn_nb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComplementNB \n",
      " Accuracy score:  0.6260062339070335 \n",
      " Precision score:  0.24468202358646535 \n",
      " Recall score:  0.9795918367346939 \n",
      " F1 score:  0.3915602883788611 \n",
      " ROC AUC score:  0.778038483064141 \n",
      "\n",
      "GaussianNB \n",
      " Accuracy score:  0.63875863938203 \n",
      " Precision score:  0.25081451681446015 \n",
      " Recall score:  0.9766133480419195 \n",
      " F1 score:  0.39912537757540234 \n",
      " ROC AUC score:  0.7840270293705156 \n",
      "\n",
      "BernoulliNB \n",
      " Accuracy score:  0.6461986719067624 \n",
      " Precision score:  0.25431059339138457 \n",
      " Recall score:  0.972972972972973 \n",
      " F1 score:  0.40322764989599286 \n",
      " ROC AUC score:  0.7867027862161118 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "score([compl_nb_clf, gaus_nb_clf, brn_nb_clf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison Naive Bayes models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see our models give us good results. In my opinion we should use GaussianNB, because it could work online and we can send info to her quickly without collection big amount of data to teach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tried a lot of models, but our best is Gaussian Naive Bayes. So we should improve it later for faster working. All files of models you can file in folder 'models', they are in rar archive. Main model will be with this file.\n",
    "\n",
    "What we could say in conclusion of our project?\n",
    "\n",
    "This was intesting experience. We analyse our data from step to step. We got working model, which we could use in real world practice. In my opinion I can reach the goal, which get in the beggining. Our managers would make a miss call, but they got 97% of all potential clients with 25% precision of call. So we got 1/4 of potential clients.\n",
    "\n",
    "Classification report and saving model you can see under this post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.70      0.81     64725\n",
      "           1       0.29      0.88      0.44      9065\n",
      "\n",
      "    accuracy                           0.72     73790\n",
      "   macro avg       0.63      0.79      0.63     73790\n",
      "weighted avg       0.89      0.72      0.77     73790\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "final_clf = GaussianNB()\n",
    "final_clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predicted = final_clf.predict(X_test)\n",
    "print(classification_report(y_test, predicted))\n",
    "\n",
    "dump(final_clf, 'final_clf.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 396,
   "position": {
    "height": "418px",
    "left": "594px",
    "right": "20px",
    "top": "83px",
    "width": "603px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
